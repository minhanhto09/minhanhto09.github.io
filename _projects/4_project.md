---
layout: page
title: Text-to-Image Synthesis Using Conditional-VAE
description: Exploring how Conditional Variational Autoencoders generate images from textual descriptions.
img: assets/img/19.jpeg
importance: 4
category: deep learning
---

Imagine a model that can transform words into imagesâ€”turning a simple description into a vivid, visual representation. In this project, we explored the power of **Conditional Variational Autoencoders (CVAE)** for generating images from text. By training models on datasets like Fashion-MNIST and MS-COCO, we examined how well these models can capture semantic meaning and produce images that reflect the nuances of both short labels and detailed captions. 

Our approach integrated advanced feature extraction techniques (e.g., **CLIP** and **Seq2Seq with Gated Fusion**) to enhance the generation process, while also addressing challenges like image sharpness and fine-grained details. This project lays the groundwork for future improvements in generative models, particularly in applications where blending textual and visual data is essential.

Find all the details in the full project report below:

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        <object data="/assets/pdf/cvae.pdf" type="application/pdf" width="100%" height="800px">
            <p>It appears you don't have a PDF plugin for this browser. You can <a href="/assets/pdf/cvae.pdf">click here to download the PDF file.</a></p>
        </object>
    </div>
</div>
